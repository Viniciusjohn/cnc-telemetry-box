# ðŸŽ¯ CNC Telemetry â€” Roadmap Executivo (Revisado)
**Data:** 2025-11-05  
**VersÃ£o:** 2.0 (baseado em feedback executivo)  
**Foco:** Valor em 30 dias + Gates objetivos + MÃ©tricas OEE/SLA

---

## ðŸš€ EstratÃ©gia: Valor RÃ¡pido â†’ Escala SÃ³lida â†’ Enterprise

### PrincÃ­pios
1. **Valor em 30 dias:** HistÃ³rico + Alertas + Multi-mÃ¡quina (F5-F7)
2. **ML/Edge em Q2'26:** Base sÃ³lida antes de complexidade
3. **OEE como Ã¢ncora:** MÃ©trica universal para ROI
4. **Gates objetivos:** MÃ©tricas mensurÃ¡veis, nÃ£o opiniÃ£o
5. **Conformidade desde cedo:** SOC 2/ISO 27001 trilha definida

---

## ï¿½ï¿½ Horizonte de ExecuÃ§Ã£o

### âš¡ Agora â†’ 30 Dias â€” FUNDAÃ‡ÃƒO SÃ“LIDA (F5-F7)
**Objetivo:** Travar valor comercial com histÃ³rico, alertas proativos e multi-mÃ¡quina

#### **Gate 5: HistÃ³rico 30 Dias (TimescaleDB)**
**Prazo:** Semana 1-2 (7-14 dias)

**Entregas:**
- PostgreSQL 15+ com extensÃ£o TimescaleDB
- Hypertable `telemetry` com particionamento temporal
- Retention policy (30 dias automÃ¡tico)
- Continuous aggregates (5min, 1h, 1d)
- Endpoint `/v1/machines/{id}/history?from=X&to=Y&resolution=5m`

**ImplementaÃ§Ã£o:**
```sql
-- Schema TimescaleDB
CREATE EXTENSION IF NOT EXISTS timescaledb;

CREATE TABLE telemetry (
  ts TIMESTAMPTZ NOT NULL,
  machine_id TEXT NOT NULL,
  rpm DOUBLE PRECISION CHECK (rpm >= 0),
  feed_mm_min DOUBLE PRECISION CHECK (feed_mm_min >= 0),
  state TEXT CHECK (state IN ('running','stopped','idle')),
  sequence BIGINT,
  src TEXT DEFAULT 'mtconnect',
  ingested_at TIMESTAMPTZ DEFAULT NOW()
);

SELECT create_hypertable('telemetry', 'ts', if_not_exists=>TRUE);

-- Ãndices otimizados
CREATE INDEX idx_machine_ts ON telemetry(machine_id, ts DESC);
CREATE INDEX idx_state ON telemetry(state, ts DESC) WHERE state \!= 'idle';

-- Retention policy (30 dias)
SELECT add_retention_policy('telemetry', INTERVAL '30 days');

-- Continuous aggregates (5min)
CREATE MATERIALIZED VIEW telemetry_5m
WITH (timescaledb.continuous) AS
  SELECT 
    time_bucket('5 minutes', ts) AS bucket,
    machine_id,
    AVG(rpm) AS rpm_avg,
    MAX(rpm) AS rpm_max,
    MIN(rpm) AS rpm_min,
    AVG(feed_mm_min) AS feed_avg,
    MAX(feed_mm_min) AS feed_max,
    COUNT(*) AS sample_count,
    MODE() WITHIN GROUP (ORDER BY state) AS state_mode
  FROM telemetry
  GROUP BY bucket, machine_id
  WITH NO DATA;

SELECT add_continuous_aggregate_policy('telemetry_5m',
  start_offset => INTERVAL '1 hour',
  end_offset => INTERVAL '5 minutes',
  schedule_interval => INTERVAL '5 minutes');

-- Aggregate 1h (para dashboard diÃ¡rio)
CREATE MATERIALIZED VIEW telemetry_1h
WITH (timescaledb.continuous) AS
  SELECT 
    time_bucket('1 hour', bucket) AS bucket,
    machine_id,
    AVG(rpm_avg) AS rpm_avg,
    MAX(rpm_max) AS rpm_max,
    AVG(feed_avg) AS feed_avg,
    SUM(sample_count) AS sample_count
  FROM telemetry_5m
  GROUP BY 1, 2
  WITH NO DATA;
```

**CritÃ©rios de Aceite (G5):**
- âœ… IngestÃ£o â‰¥ 5000 pontos/min (83 pontos/s)
- âœ… SELECT P95 < 200ms em `telemetry_5m`
- âœ… CompressÃ£o ativa apÃ³s 7 dias (reduz 70% storage)
- âœ… Query histÃ³rico 30 dias < 2s

**ValidaÃ§Ã£o:**
```bash
# Load test (ingestÃ£o)
for i in {1..5000}; do
  curl -X POST http://localhost:8001/v1/telemetry/ingest \
    -H 'Content-Type: application/json' \
    -d "{\"machine_id\":\"TEST-001\",\"timestamp\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"rpm\":4500,\"feed_mm_min\":1400,\"state\":\"running\"}"
done &

# Query performance
psql -c "EXPLAIN ANALYZE SELECT * FROM telemetry_5m WHERE machine_id='CNC-SIM-001' AND bucket > NOW() - INTERVAL '7 days';"
```

**ReferÃªncia:** https://docs.timescale.com/

---

#### **Gate 6: Alertas Proativos (Slack/Webhook)**
**Prazo:** Semana 2-3 (7-10 dias)

**Entregas:**
- Engine de regras (YAML config)
- Celery worker para avaliaÃ§Ã£o assÃ­ncrona
- IntegraÃ§Ã£o Slack (incoming webhooks)
- Webhook genÃ©rico (HTTP POST)
- Dashboard de alertas ativos
- Dedupe (1 alerta/min por regra)

**Schema de Regras:**
```yaml
# alerts.yaml
alerts:
  - name: machine_stopped_long
    machine_id: "*"  # todas
    condition: |
      state == 'stopped' AND 
      duration_seconds > 600  # 10 min
    severity: warning
    channels:
      - type: slack
        webhook: ${SLACK_WEBHOOK_URL}
        template: "ðŸ”´ {machine_id} parada hÃ¡ {duration_min} min"
      - type: webhook
        url: ${ALERT_WEBHOOK_URL}
        
  - name: rpm_anomaly
    machine_id: "ABR-850"
    condition: |
      rpm > 0 AND rpm < 1000 AND state == 'running'  # RPM baixo anormal
    severity: critical
    channels:
      - type: slack

  - name: feed_zero_running
    condition: |
      feed_mm_min == 0 AND state == 'running'  # Feed parado em execuÃ§Ã£o
    severity: warning
    duration_seconds: 15  # sÃ³ alerta se persistir 15s
```

**ImplementaÃ§Ã£o (Engine):**
```python
# backend/app/services/alerts.py
from celery import Celery
import yaml
import httpx
from datetime import datetime, timedelta

celery_app = Celery('alerts', broker='redis://localhost:6379/0')

@celery_app.task
def evaluate_alerts():
    rules = load_rules('alerts.yaml')
    recent_data = query_recent_telemetry(seconds=60)
    
    for rule in rules:
        matches = eval_condition(rule['condition'], recent_data)
        if matches:
            if not is_recently_fired(rule['name'], minutes=1):
                send_alert(rule, matches)

def send_alert(rule, data):
    for channel in rule['channels']:
        if channel['type'] == 'slack':
            send_slack(channel['webhook'], format_message(rule, data))
        elif channel['type'] == 'webhook':
            send_webhook(channel['url'], data)
```

**CritÃ©rios de Aceite (G6):**
- âœ… Alerta < 5s apÃ³s condiÃ§Ã£o satisfeita
- âœ… Dedupe: mÃ¡x 1 alerta/min por regra
- âœ… Slack recebe mensagem formatada
- âœ… Zero falsos positivos em 24h de teste

**ValidaÃ§Ã£o:**
```bash
# Simular condiÃ§Ã£o de alerta
curl -X POST http://localhost:8001/v1/telemetry/ingest \
  -d '{"machine_id":"TEST-001","timestamp":"2025-11-05T10:00:00Z","rpm":0,"feed_mm_min":0,"state":"stopped"}'

# Aguardar 11 minutos (para trigger machine_stopped_long)
sleep 660

# Verificar Slack recebeu notificaÃ§Ã£o
curl -X GET http://localhost:8001/v1/alerts/history | jq
```

---

#### **Gate 7: Multi-MÃ¡quina (10 CNCs SimultÃ¢neos)**
**Prazo:** Semana 3-4 (7-10 dias)

**Entregas:**
- Adapter multi-threaded (ThreadPoolExecutor)
- Config YAML para lista de mÃ¡quinas
- Dashboard: Grid de mÃ¡quinas
- Filtros: estado, planta, modelo
- Endpoint `/v1/fleet/summary`
- AgregaÃ§Ã£o: OEE mÃ©dio, uptime total

**Config Multi-MÃ¡quina:**
```yaml
# machines.yaml
machines:
  - id: ABR-850
    agent_url: http://10.0.1.50:5000
    plant: "Planta 1"
    model: "ABR-850"
    
  - id: CNC-SIM-001
    agent_url: http://localhost:5000
    plant: "Lab"
    model: "Simulator"
    
  - id: CNC-SIM-002
    agent_url: http://localhost:5001
    plant: "Lab"
    model: "Simulator"
    
  # ... atÃ© 10 mÃ¡quinas
```

**Adapter Multi-Thread:**
```python
# backend/mtconnect_adapter.py
from concurrent.futures import ThreadPoolExecutor
import yaml

def run_multi_machine(config_file='machines.yaml'):
    machines = yaml.safe_load(open(config_file))['machines']
    
    with ThreadPoolExecutor(max_workers=len(machines)) as executor:
        futures = []
        for machine in machines:
            adapter = MTConnectAdapter(
                agent_url=machine['agent_url'],
                api_url=API_URL,
                machine_id=machine['id']
            )
            futures.append(executor.submit(asyncio.run, adapter.run()))
        
        # Wait all
        for future in futures:
            future.result()
```

**Fleet Summary API:**
```python
@router.get("/v1/fleet/summary")
def get_fleet_summary():
    machines = db.query("""
        SELECT 
            COUNT(*) AS total,
            SUM(CASE WHEN state='running' THEN 1 ELSE 0 END) AS running,
            SUM(CASE WHEN state='stopped' THEN 1 ELSE 0 END) AS stopped,
            SUM(CASE WHEN state='idle' THEN 1 ELSE 0 END) AS idle,
            AVG(rpm) AS avg_rpm,
            AVG(oee_availability * oee_performance) AS avg_oee
        FROM latest_status
    """)
    return machines
```

**CritÃ©rios de Aceite (G7):**
- âœ… 10 mÃ¡quinas simultÃ¢neas sem degradaÃ§Ã£o
- âœ… Perda de dados < 0.5% em 1h
- âœ… P95 latÃªncia ingestÃ£o < 2s
- âœ… Falha em 1 mÃ¡quina nÃ£o afeta outras
- âœ… Dashboard renderiza < 1s com 10 mÃ¡quinas

**ValidaÃ§Ã£o:**
```bash
# Subir 10 simuladores em portas diferentes
for i in {5000..5009}; do
  python3 scripts/mtconnect_simulator.py --port $i &
done

# Configurar machines.yaml com 10 entradas

# Rodar adapter multi-mÃ¡quina
python3 backend/mtconnect_adapter.py --config machines.yaml

# Load test
ab -n 1000 -c 10 http://localhost:8001/v1/fleet/summary

# Validar mÃ©tricas
psql -c "SELECT machine_id, COUNT(*) FROM telemetry WHERE ts > NOW() - INTERVAL '1 hour' GROUP BY machine_id;"
```

---

### ðŸ“Š PrÃ³ximos 3-9 Meses â€” ANALYTICS & OBSERVABILIDADE (F8-F12)

#### **Gate 8: OEE & Analytics Dashboard**
**Prazo:** Q1 2026 (4-6 semanas)

**OEE Canonical:**
```
OEE = Availability Ã— Performance Ã— Quality

Availability = Operating Time / Planned Production Time
Performance = (Actual Output / Theoretical Max Output)
Quality = (Good Parts / Total Parts Produced)
```

**Entregas:**
- CÃ¡lculo OEE por mÃ¡quina/turno/dia
- Dashboard: Cards OEE, Trends, Heatmaps
- Endpoint `/v1/machines/{id}/oee?date=YYYY-MM-DD`
- AgregaÃ§Ãµes: OEE mÃ©dio por planta
- Export PDF/CSV

**Schema OEE:**
```sql
CREATE TABLE oee_daily (
  date DATE NOT NULL,
  machine_id TEXT NOT NULL,
  planned_time_min INT NOT NULL,
  operating_time_min INT NOT NULL,
  actual_parts INT,
  theoretical_parts INT,
  good_parts INT,
  availability FLOAT,
  performance FLOAT,
  quality FLOAT,
  oee FLOAT,
  PRIMARY KEY (date, machine_id)
);
```

**CritÃ©rios de Aceite (G8):**
- âœ… OEE calculado por mÃ¡quina/turno/dia
- âœ… Dashboard mostra trends 30 dias
- âœ… Query OEE < 500ms
- âœ… Export PDF em < 3s

---

#### **Gate 9: OPC-UA Bridge (IEC 62541)**
**Prazo:** Q1 2026 (3-4 semanas)

**Entregas:**
- Cliente OPC-UA (asyncua)
- Auto-discovery de nodes
- Mapeamento Speed/Feed/Execution â†’ schema
- CoexistÃªncia com MTConnect

**PoC:**
```python
from asyncua import Client

async def opc_ua_adapter():
    client = Client("opc.tcp://10.0.1.100:4840")
    await client.connect()
    
    # Browse nodes
    root = client.get_root_node()
    cnc_node = await root.get_child(["Objects", "CNC", "Machine1"])
    
    # Subscribe
    speed_node = await cnc_node.get_child(["Speed"])
    feed_node = await cnc_node.get_child(["Feed"])
    
    while True:
        speed = await speed_node.read_value()
        feed = await feed_node.read_value()
        
        await post_ingest({
            "machine_id": "OPC-001",
            "rpm": speed,
            "feed_mm_min": feed * 60,  # mm/s â†’ mm/min
            "state": "running"
        })
        await asyncio.sleep(2)
```

**CritÃ©rios de Aceite (G9):**
- âœ… 30 min amostras sem perda
- âœ… Doc de mapeamento nodes â†’ schema
- âœ… Coexiste com MTConnect

---

#### **Gate 10: Observabilidade (OpenTelemetry)**
**Prazo:** Q2 2026 (2-3 semanas)

**Entregas:**
- InstrumentaÃ§Ã£o FastAPI (OTEL)
- MÃ©tricas: ingest_rate, queue_lag, api_latency
- Traces: /ingest E2E
- Export para Jaeger/Prometheus

**InstrumentaÃ§Ã£o:**
```python
# backend/app.py
from opentelemetry import trace, metrics
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# Setup
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)
trace.get_tracer_provider().add_span_processor(
    BatchSpanProcessor(OTLPSpanExporter(endpoint="http://localhost:4317"))
)

# Trace /ingest
@app.post("/v1/telemetry/ingest")
@tracer.start_as_current_span("ingest_telemetry")
async def ingest(payload: TelemetryPayload):
    span = trace.get_current_span()
    span.set_attribute("machine_id", payload.machine_id)
    # ... lÃ³gica
```

**CritÃ©rios de Aceite (G10):**
- âœ… MÃ©tricas exportadas (ingest_rate, lag)
- âœ… Traces de /ingest no Jaeger
- âœ… Dashboards Grafana com SLIs

**ReferÃªncia:** https://opentelemetry.io/

---

#### **Gate 11: Edge PoC (MQTT + Buffer Offline)**
**Prazo:** Q2 2026 (4 semanas)

**Entregas:**
- MQTT pub/sub (Mosquitto)
- Buffer local (SQLite) durante offline
- Re-envio automÃ¡tico apÃ³s reconexÃ£o
- QoS 1 (at least once)

**Arquitetura:**
```
CNC â†’ Adapter Edge â†’ MQTT Broker â†’ Cloud Subscriber â†’ Backend
              â†“
         SQLite Buffer
         (durante offline)
```

**ImplementaÃ§Ã£o:**
```python
import paho.mqtt.client as mqtt
import sqlite3

class EdgeAdapter:
    def __init__(self):
        self.buffer = sqlite3.connect('edge_buffer.db')
        self.mqtt_client = mqtt.Client()
        self.mqtt_client.on_connect = self.on_connect
        self.mqtt_client.connect("mqtt.example.com", 1883)
    
    def publish_telemetry(self, data):
        try:
            self.mqtt_client.publish(
                f"telemetry/{data['machine_id']}", 
                json.dumps(data), 
                qos=1
            )
        except:
            # Offline: buffer localmente
            self.buffer_insert(data)
    
    def on_connect(self, client, userdata, flags, rc):
        # Reconectou: enviar buffer
        buffered = self.buffer_read()
        for item in buffered:
            self.publish_telemetry(item)
        self.buffer_clear()
```

**CritÃ©rios de Aceite (G11):**
- âœ… 15 min offline sem perda de dados
- âœ… Re-envio automÃ¡tico apÃ³s reconexÃ£o
- âœ… QoS 1 garantido

---

#### **Gate 12: Trilhas de Conformidade (SOC 2 / ISO 27001)**
**Prazo:** Q3-Q4 2026 (16 semanas + auditoria)

**SOC 2 Trust Services Criteria (TSC):**
- **CC6.1:** Change Management (CI/CD, Git commits, aprovaÃ§Ãµes)
- **CC6.2:** Access Control (RBAC, MFA, audit log)
- **CC7.2:** Logging & Monitoring (90 dias retenÃ§Ã£o)

**ISO 27001 Anexo A:**
- **A.9.2:** User access management
- **A.12.3:** Information backup
- **A.18.1:** Compliance com requisitos legais

**AÃ§Ãµes Imediatas:**
- [ ] PolÃ­tica de seguranÃ§a aprovada (escopo ISMS)
- [ ] CI/CD com aprovaÃ§Ã£o (GitHub branch protection)
- [ ] RBAC implementado (admin, operator, viewer)
- [ ] Audit log 90 dias (PostgreSQL table)
- [ ] Encryption at rest (AES-256)
- [ ] Encryption in transit (TLS 1.3)

**CritÃ©rios de Aceite (G12):**
- âœ… PolÃ­tica de seguranÃ§a aprovada
- âœ… EvidÃªncias mÃ­nimas: CI/CD, RBAC, logs
- âœ… Backup automÃ¡tico diÃ¡rio
- âœ… Penetration test sem critical findings

---

### ðŸŒ 9-24 Meses â€” ENTERPRISE SCALE (F13-F20)

#### **F13:** Multi-Tenant SaaS (schema-per-tenant)
#### **F14:** IntegraÃ§Ãµes ERP/MES (SAP, Wonderware)
#### **F15:** Mobile App (React Native)
#### **F16:** CertificaÃ§Ãµes (SOC 2 Type II, ISO 27001)
#### **F17:** Escalonamento Multi-RegiÃ£o (AWS/GCP)
#### **F18:** Plugin Marketplace
#### **F19:** AI Copilot (LangChain + GPT-4)
#### **F20:** Global Scale (K8s multi-cluster)

---

## ðŸ“Š SLOs e MÃ©tricas

### SLIs (Service Level Indicators)
- **Availability:** Uptime API (target: 99.5% Q4, 99.9% Q2'26)
- **Latency:** P95 /ingest < 2s, P99 < 5s
- **Durability:** Perda de dados < 0.5%
- **Throughput:** IngestÃ£o â‰¥ 5000 pontos/min

### OEE Targets (Cliente)
- **Q4'25:** Baseline (medir sem alvo)
- **Q1'26:** OEE mÃ©dio > 60%
- **Q2'26:** OEE mÃ©dio > 75%

### Business Metrics
- **MÃ¡quinas monitoradas:** 1 â†’ 10 (30d) â†’ 50 (Q1) â†’ 100 (Q2)
- **Clientes:** 1 â†’ 3 (Q1) â†’ 10 (Q2)
- **ARR:** $0 â†’ $10k (Q1) â†’ $50k (Q2)

---

## ðŸš§ Riscos e MitigaÃ§Ãµes

| Risco | Impacto | MitigaÃ§Ã£o |
|-------|---------|-----------|
| **Heterogeneidade MTConnect** | Alto | Tabela de mapeamento por fornecedor/versÃ£o |
| **Cardinalidade explode DB** | CrÃ­tico | RetenÃ§Ã£o 30d + continuous aggregates |
| **Vendor lock-in edge** | MÃ©dio | Alternativas: Greengrass, Azure IoT Edge |
| **Compliance atraso** | Alto | Milestones trimestrais SOC 2/ISO 27001 |
| **OPC-UA complexidade** | MÃ©dio | PoC limitado a 3 fornecedores primeiro |

---

## ðŸŽ¯ PrÃ³ximo Passo CirÃºrgico

### Hoje (5 Nov)
- [x] Roadmap revisado
- [ ] Iniciar F5: Criar schema TimescaleDB
- [ ] Setup PostgreSQL + TimescaleDB extension

### Esta Semana (6-10 Nov)
- [ ] F4 campo: Soak 30 min ABR-850 + registrar OEE diÃ¡rio
- [ ] F5: Hypertable + retention policy
- [ ] F5: Migrar /ingest para gravar em DB

### PrÃ³ximos 30 Dias
- [ ] F5 completo (histÃ³rico 30d)
- [ ] F6 completo (alertas Slack)
- [ ] F7 completo (10 CNCs)
- [ ] Primeira venda (cliente beta pagante)

---

## ðŸ“š Bases Normativas

### MTConnect
- **SequÃªncias:** `Header.nextSequence` + `from` em `/sample`
- **Incremental:** Consumo sem perdas
- **Spec:** https://www.mtconnect.org/

### OPC-UA (IEC 62541)
- **Interoperabilidade:** PadrÃ£o industrial universal
- **CoexistÃªncia:** MTConnect + OPC-UA simultaneamente
- **Spec:** https://opcfoundation.org/

### OEE
- **FÃ³rmula:** A Ã— P Ã— Q
- **ROI:** MÃ©trica Ã¢ncora para cliente
- **Ref:** ISA-95, SEMI E10

### MQTT
- **Pub/Sub:** TÃ³picos + QoS para links ruins
- **Edge:** Ideal para telemetria edgeâ†”cloud
- **Spec:** OASIS MQTT 5.0

### OpenTelemetry
- **Observabilidade:** MÃ©tricas + Traces + Logs
- **SLOs:** Facilita troubleshooting
- **Ref:** https://opentelemetry.io/

### TimescaleDB
- **Time-Series:** AgregaÃ§Ãµes + compressÃ£o nativa
- **PostgreSQL:** CompatÃ­vel com ecossistema
- **Docs:** https://docs.timescale.com/

---

**VersÃ£o:** 2.0  
**Autor:** Vinicius John  
**Ãšltima AtualizaÃ§Ã£o:** 2025-11-05  
**PrÃ³xima RevisÃ£o:** 2025-12-05
